{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Graph AutoEncoders (GAE) &\n",
    "## Variational Graph Autoencoders (VGAE)\n",
    "\n",
    "https://www.youtube.com/watch?v=qA6U4nIK62E\n",
    "Paper for Ref: https://arxiv.org/pdf/1611.07308.pdf"
   ],
   "metadata": {
    "id": "f2uVLM5pZxp2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqdcxiZ3Y51j",
    "outputId": "dc2c772e-7e2a-4be7-acd0-30bb36ffae67"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.12.1+cu113\n",
      "\u001B[K     |████████████████████████████████| 7.9 MB 2.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 3.5 MB 2.9 MB/s \n",
      "\u001B[?25h  Building wheel for torch-geometric (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges"
   ],
   "metadata": {
    "id": "rDVKeHWcZRwN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Graph AutoEncoders (GAE)\n"
   ],
   "metadata": {
    "id": "Utle_lhxi4AS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**CLASS GAE[encoder, decoder=None]**\n",
    "\n",
    "The Graph Auto-Encoder model from the \"Variational Graph Auto-Encoder\" paper based on user-defined enconder and decoder models.\n",
    "\n",
    "PARAMETERS\n",
    "- encoder(Module) - The encoder module\n",
    "- decoder (Module, optional) - The decoder module. If set to **None**. will default to **torch_geometric.nn.models.InnerProductDecoder**.\n",
    "\n"
   ],
   "metadata": {
    "id": "ieJIaGsWaEyY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Load Data"
   ],
   "metadata": {
    "id": "cycKMykMaLov"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "dataset.data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCtTxx3baPmg",
    "outputId": "c48d6adb-f13b-4cd6-f235-035772e133a2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = dataset[0]\n",
    "# reset the train_mask and validation_mask\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNfsc_dNcJCl",
    "outputId": "cf7490cf-9627-43c6-d934-9ce71fe7ce93"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# this function split the edges of the data producing the same dataset with negative and positive edges\n",
    "data = train_test_split_edges(data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eG09TmOwcY6k",
    "outputId": "55d4ed0a-31b4-4c79-d2dc-c956c8fdffb2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvlj0QSQcv_l",
    "outputId": "0d0232cb-2624-484d-a2c1-8586871589e4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], y=[3327], val_pos_edge_index=[2, 227], test_pos_edge_index=[2, 455], train_pos_edge_index=[2, 7740], train_neg_adj_mask=[3327, 3327], val_neg_edge_index=[2, 227], test_neg_edge_index=[2, 455])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Define the Encoder"
   ],
   "metadata": {
    "id": "08f2QR9Vc5hS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        # graph convolutional network\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)"
   ],
   "metadata": {
    "id": "jpAG1ikZcxFk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Efm8r1p4e0xe",
    "outputId": "6995802e-35d1-4ca9-f600-9728b81a1dfa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 Define the Autoencoder"
   ],
   "metadata": {
    "id": "LeEb52jedfY3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import GAE"
   ],
   "metadata": {
    "id": "OU7p9gl3ddm0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "id": "V1iEggDsdlvy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4mpCP7AeLqU",
    "outputId": "b425ff69-4036-4758-e76d-8a737c11110f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GAE(\n",
       "  (encoder): GCNEncoder(\n",
       "    (conv1): GCNConv(3703, 4)\n",
       "    (conv2): GCNConv(4, 2)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    #if args.variational:\n",
    "    #   loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ],
   "metadata": {
    "id": "64VMOzW-dtb0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ygd08lXZecfm",
    "outputId": "ee73d80c-0c28-4704-f70c-11437d0f52d0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001, AUC: 0.6242, AP: 0.6535\n",
      "Epoch: 002, AUC: 0.6663, AP: 0.7081\n",
      "Epoch: 003, AUC: 0.6633, AP: 0.7040\n",
      "Epoch: 004, AUC: 0.6683, AP: 0.7069\n",
      "Epoch: 005, AUC: 0.6730, AP: 0.7114\n",
      "Epoch: 006, AUC: 0.6762, AP: 0.7152\n",
      "Epoch: 007, AUC: 0.6782, AP: 0.7190\n",
      "Epoch: 008, AUC: 0.6809, AP: 0.7231\n",
      "Epoch: 009, AUC: 0.6816, AP: 0.7243\n",
      "Epoch: 010, AUC: 0.6817, AP: 0.7246\n",
      "Epoch: 011, AUC: 0.6813, AP: 0.7244\n",
      "Epoch: 012, AUC: 0.6812, AP: 0.7250\n",
      "Epoch: 013, AUC: 0.6814, AP: 0.7264\n",
      "Epoch: 014, AUC: 0.6822, AP: 0.7287\n",
      "Epoch: 015, AUC: 0.6828, AP: 0.7308\n",
      "Epoch: 016, AUC: 0.6838, AP: 0.7329\n",
      "Epoch: 017, AUC: 0.6841, AP: 0.7344\n",
      "Epoch: 018, AUC: 0.6846, AP: 0.7362\n",
      "Epoch: 019, AUC: 0.6848, AP: 0.7378\n",
      "Epoch: 020, AUC: 0.6851, AP: 0.7397\n",
      "Epoch: 021, AUC: 0.6854, AP: 0.7414\n",
      "Epoch: 022, AUC: 0.6861, AP: 0.7437\n",
      "Epoch: 023, AUC: 0.6864, AP: 0.7453\n",
      "Epoch: 024, AUC: 0.6871, AP: 0.7472\n",
      "Epoch: 025, AUC: 0.6882, AP: 0.7491\n",
      "Epoch: 026, AUC: 0.6886, AP: 0.7504\n",
      "Epoch: 027, AUC: 0.6897, AP: 0.7521\n",
      "Epoch: 028, AUC: 0.6907, AP: 0.7538\n",
      "Epoch: 029, AUC: 0.6913, AP: 0.7547\n",
      "Epoch: 030, AUC: 0.6924, AP: 0.7562\n",
      "Epoch: 031, AUC: 0.6936, AP: 0.7575\n",
      "Epoch: 032, AUC: 0.6951, AP: 0.7588\n",
      "Epoch: 033, AUC: 0.6970, AP: 0.7606\n",
      "Epoch: 034, AUC: 0.6991, AP: 0.7621\n",
      "Epoch: 035, AUC: 0.7020, AP: 0.7637\n",
      "Epoch: 036, AUC: 0.7058, AP: 0.7657\n",
      "Epoch: 037, AUC: 0.7111, AP: 0.7686\n",
      "Epoch: 038, AUC: 0.7172, AP: 0.7716\n",
      "Epoch: 039, AUC: 0.7247, AP: 0.7750\n",
      "Epoch: 040, AUC: 0.7334, AP: 0.7792\n",
      "Epoch: 041, AUC: 0.7413, AP: 0.7829\n",
      "Epoch: 042, AUC: 0.7501, AP: 0.7873\n",
      "Epoch: 043, AUC: 0.7605, AP: 0.7928\n",
      "Epoch: 044, AUC: 0.7737, AP: 0.7999\n",
      "Epoch: 045, AUC: 0.7872, AP: 0.8078\n",
      "Epoch: 046, AUC: 0.7981, AP: 0.8148\n",
      "Epoch: 047, AUC: 0.8065, AP: 0.8206\n",
      "Epoch: 048, AUC: 0.8114, AP: 0.8240\n",
      "Epoch: 049, AUC: 0.8157, AP: 0.8270\n",
      "Epoch: 050, AUC: 0.8211, AP: 0.8310\n",
      "Epoch: 051, AUC: 0.8263, AP: 0.8348\n",
      "Epoch: 052, AUC: 0.8307, AP: 0.8382\n",
      "Epoch: 053, AUC: 0.8344, AP: 0.8412\n",
      "Epoch: 054, AUC: 0.8371, AP: 0.8435\n",
      "Epoch: 055, AUC: 0.8382, AP: 0.8442\n",
      "Epoch: 056, AUC: 0.8388, AP: 0.8441\n",
      "Epoch: 057, AUC: 0.8394, AP: 0.8441\n",
      "Epoch: 058, AUC: 0.8408, AP: 0.8451\n",
      "Epoch: 059, AUC: 0.8425, AP: 0.8472\n",
      "Epoch: 060, AUC: 0.8433, AP: 0.8484\n",
      "Epoch: 061, AUC: 0.8436, AP: 0.8488\n",
      "Epoch: 062, AUC: 0.8445, AP: 0.8496\n",
      "Epoch: 063, AUC: 0.8454, AP: 0.8498\n",
      "Epoch: 064, AUC: 0.8464, AP: 0.8501\n",
      "Epoch: 065, AUC: 0.8473, AP: 0.8508\n",
      "Epoch: 066, AUC: 0.8484, AP: 0.8523\n",
      "Epoch: 067, AUC: 0.8492, AP: 0.8535\n",
      "Epoch: 068, AUC: 0.8502, AP: 0.8544\n",
      "Epoch: 069, AUC: 0.8518, AP: 0.8559\n",
      "Epoch: 070, AUC: 0.8532, AP: 0.8569\n",
      "Epoch: 071, AUC: 0.8543, AP: 0.8579\n",
      "Epoch: 072, AUC: 0.8556, AP: 0.8595\n",
      "Epoch: 073, AUC: 0.8571, AP: 0.8614\n",
      "Epoch: 074, AUC: 0.8583, AP: 0.8627\n",
      "Epoch: 075, AUC: 0.8595, AP: 0.8642\n",
      "Epoch: 076, AUC: 0.8610, AP: 0.8657\n",
      "Epoch: 077, AUC: 0.8621, AP: 0.8667\n",
      "Epoch: 078, AUC: 0.8633, AP: 0.8675\n",
      "Epoch: 079, AUC: 0.8648, AP: 0.8694\n",
      "Epoch: 080, AUC: 0.8662, AP: 0.8712\n",
      "Epoch: 081, AUC: 0.8676, AP: 0.8731\n",
      "Epoch: 082, AUC: 0.8690, AP: 0.8746\n",
      "Epoch: 083, AUC: 0.8701, AP: 0.8753\n",
      "Epoch: 084, AUC: 0.8709, AP: 0.8755\n",
      "Epoch: 085, AUC: 0.8716, AP: 0.8760\n",
      "Epoch: 086, AUC: 0.8724, AP: 0.8769\n",
      "Epoch: 087, AUC: 0.8740, AP: 0.8788\n",
      "Epoch: 088, AUC: 0.8748, AP: 0.8801\n",
      "Epoch: 089, AUC: 0.8752, AP: 0.8805\n",
      "Epoch: 090, AUC: 0.8760, AP: 0.8810\n",
      "Epoch: 091, AUC: 0.8765, AP: 0.8812\n",
      "Epoch: 092, AUC: 0.8763, AP: 0.8807\n",
      "Epoch: 093, AUC: 0.8759, AP: 0.8801\n",
      "Epoch: 094, AUC: 0.8758, AP: 0.8799\n",
      "Epoch: 095, AUC: 0.8767, AP: 0.8806\n",
      "Epoch: 096, AUC: 0.8776, AP: 0.8813\n",
      "Epoch: 097, AUC: 0.8778, AP: 0.8814\n",
      "Epoch: 098, AUC: 0.8777, AP: 0.8812\n",
      "Epoch: 099, AUC: 0.8777, AP: 0.8811\n",
      "Epoch: 100, AUC: 0.8777, AP: 0.8808\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Z = model.encode(x, train_pos_edge_index)\n",
    "Z"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jB16fbXaedX1",
    "outputId": "7b8bb93f-8b8a-4009-e7c2-e3d6b8374d41"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.8494, -0.4407],\n",
       "        [-0.3673, -1.1666],\n",
       "        [ 0.3398,  1.1432],\n",
       "        ...,\n",
       "        [ 0.4383, -1.2611],\n",
       "        [ 0.9726,  0.3775],\n",
       "        [ 1.4920,  0.6976]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Are the results (AUC) and (AP) easy to read and compare?"
   ],
   "metadata": {
    "id": "OB8MxQPWfGcQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.4 Use Tensorboard"
   ],
   "metadata": {
    "id": "PoA0csb4fQID"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "id": "d-bWv7_BesXU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "id": "QCs5uDWnfV8X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.5 Import Tensorboard"
   ],
   "metadata": {
    "id": "-Xg3guN1fgJh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "writer = SummaryWriter('runs/GAE1_experiment_'+'2d_100_epochs')"
   ],
   "metadata": {
    "id": "p5f7asvyfZT0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc train',auc,epoch) # new line\n",
    "    writer.add_scalar('ap train',ap,epoch)   # new line"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hQfmxvVflTy",
    "outputId": "4fef9702-3c12-486c-fac2-9a4b951b047d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001, AUC: 0.6516, AP: 0.6974\n",
      "Epoch: 002, AUC: 0.6589, AP: 0.7021\n",
      "Epoch: 003, AUC: 0.6611, AP: 0.7021\n",
      "Epoch: 004, AUC: 0.6650, AP: 0.7050\n",
      "Epoch: 005, AUC: 0.6690, AP: 0.7096\n",
      "Epoch: 006, AUC: 0.6729, AP: 0.7140\n",
      "Epoch: 007, AUC: 0.6743, AP: 0.7162\n",
      "Epoch: 008, AUC: 0.6753, AP: 0.7181\n",
      "Epoch: 009, AUC: 0.6762, AP: 0.7212\n",
      "Epoch: 010, AUC: 0.6770, AP: 0.7240\n",
      "Epoch: 011, AUC: 0.6777, AP: 0.7275\n",
      "Epoch: 012, AUC: 0.6783, AP: 0.7313\n",
      "Epoch: 013, AUC: 0.6790, AP: 0.7350\n",
      "Epoch: 014, AUC: 0.6792, AP: 0.7383\n",
      "Epoch: 015, AUC: 0.6781, AP: 0.7405\n",
      "Epoch: 016, AUC: 0.6782, AP: 0.7429\n",
      "Epoch: 017, AUC: 0.6777, AP: 0.7442\n",
      "Epoch: 018, AUC: 0.6774, AP: 0.7456\n",
      "Epoch: 019, AUC: 0.6772, AP: 0.7464\n",
      "Epoch: 020, AUC: 0.6768, AP: 0.7466\n",
      "Epoch: 021, AUC: 0.6768, AP: 0.7474\n",
      "Epoch: 022, AUC: 0.6771, AP: 0.7482\n",
      "Epoch: 023, AUC: 0.6777, AP: 0.7494\n",
      "Epoch: 024, AUC: 0.6790, AP: 0.7507\n",
      "Epoch: 025, AUC: 0.6813, AP: 0.7522\n",
      "Epoch: 026, AUC: 0.6854, AP: 0.7546\n",
      "Epoch: 027, AUC: 0.6909, AP: 0.7571\n",
      "Epoch: 028, AUC: 0.6995, AP: 0.7605\n",
      "Epoch: 029, AUC: 0.7089, AP: 0.7644\n",
      "Epoch: 030, AUC: 0.7171, AP: 0.7679\n",
      "Epoch: 031, AUC: 0.7239, AP: 0.7711\n",
      "Epoch: 032, AUC: 0.7298, AP: 0.7738\n",
      "Epoch: 033, AUC: 0.7355, AP: 0.7763\n",
      "Epoch: 034, AUC: 0.7410, AP: 0.7790\n",
      "Epoch: 035, AUC: 0.7509, AP: 0.7840\n",
      "Epoch: 036, AUC: 0.7619, AP: 0.7899\n",
      "Epoch: 037, AUC: 0.7746, AP: 0.7971\n",
      "Epoch: 038, AUC: 0.7860, AP: 0.8041\n",
      "Epoch: 039, AUC: 0.7956, AP: 0.8099\n",
      "Epoch: 040, AUC: 0.8025, AP: 0.8146\n",
      "Epoch: 041, AUC: 0.8066, AP: 0.8176\n",
      "Epoch: 042, AUC: 0.8086, AP: 0.8191\n",
      "Epoch: 043, AUC: 0.8102, AP: 0.8206\n",
      "Epoch: 044, AUC: 0.8108, AP: 0.8211\n",
      "Epoch: 045, AUC: 0.8117, AP: 0.8219\n",
      "Epoch: 046, AUC: 0.8130, AP: 0.8230\n",
      "Epoch: 047, AUC: 0.8141, AP: 0.8240\n",
      "Epoch: 048, AUC: 0.8145, AP: 0.8247\n",
      "Epoch: 049, AUC: 0.8147, AP: 0.8250\n",
      "Epoch: 050, AUC: 0.8148, AP: 0.8252\n",
      "Epoch: 051, AUC: 0.8150, AP: 0.8249\n",
      "Epoch: 052, AUC: 0.8152, AP: 0.8250\n",
      "Epoch: 053, AUC: 0.8155, AP: 0.8255\n",
      "Epoch: 054, AUC: 0.8155, AP: 0.8263\n",
      "Epoch: 055, AUC: 0.8157, AP: 0.8275\n",
      "Epoch: 056, AUC: 0.8156, AP: 0.8281\n",
      "Epoch: 057, AUC: 0.8160, AP: 0.8284\n",
      "Epoch: 058, AUC: 0.8166, AP: 0.8283\n",
      "Epoch: 059, AUC: 0.8171, AP: 0.8279\n",
      "Epoch: 060, AUC: 0.8174, AP: 0.8282\n",
      "Epoch: 061, AUC: 0.8178, AP: 0.8290\n",
      "Epoch: 062, AUC: 0.8181, AP: 0.8302\n",
      "Epoch: 063, AUC: 0.8179, AP: 0.8303\n",
      "Epoch: 064, AUC: 0.8177, AP: 0.8307\n",
      "Epoch: 065, AUC: 0.8179, AP: 0.8306\n",
      "Epoch: 066, AUC: 0.8180, AP: 0.8297\n",
      "Epoch: 067, AUC: 0.8182, AP: 0.8292\n",
      "Epoch: 068, AUC: 0.8184, AP: 0.8291\n",
      "Epoch: 069, AUC: 0.8180, AP: 0.8290\n",
      "Epoch: 070, AUC: 0.8179, AP: 0.8296\n",
      "Epoch: 071, AUC: 0.8179, AP: 0.8296\n",
      "Epoch: 072, AUC: 0.8177, AP: 0.8289\n",
      "Epoch: 073, AUC: 0.8179, AP: 0.8285\n",
      "Epoch: 074, AUC: 0.8183, AP: 0.8282\n",
      "Epoch: 075, AUC: 0.8184, AP: 0.8278\n",
      "Epoch: 076, AUC: 0.8185, AP: 0.8275\n",
      "Epoch: 077, AUC: 0.8184, AP: 0.8275\n",
      "Epoch: 078, AUC: 0.8181, AP: 0.8274\n",
      "Epoch: 079, AUC: 0.8180, AP: 0.8271\n",
      "Epoch: 080, AUC: 0.8184, AP: 0.8271\n",
      "Epoch: 081, AUC: 0.8187, AP: 0.8264\n",
      "Epoch: 082, AUC: 0.8194, AP: 0.8261\n",
      "Epoch: 083, AUC: 0.8198, AP: 0.8260\n",
      "Epoch: 084, AUC: 0.8199, AP: 0.8258\n",
      "Epoch: 085, AUC: 0.8199, AP: 0.8263\n",
      "Epoch: 086, AUC: 0.8193, AP: 0.8262\n",
      "Epoch: 087, AUC: 0.8196, AP: 0.8263\n",
      "Epoch: 088, AUC: 0.8205, AP: 0.8266\n",
      "Epoch: 089, AUC: 0.8211, AP: 0.8265\n",
      "Epoch: 090, AUC: 0.8218, AP: 0.8265\n",
      "Epoch: 091, AUC: 0.8221, AP: 0.8265\n",
      "Epoch: 092, AUC: 0.8223, AP: 0.8269\n",
      "Epoch: 093, AUC: 0.8220, AP: 0.8270\n",
      "Epoch: 094, AUC: 0.8221, AP: 0.8271\n",
      "Epoch: 095, AUC: 0.8223, AP: 0.8272\n",
      "Epoch: 096, AUC: 0.8229, AP: 0.8275\n",
      "Epoch: 097, AUC: 0.8231, AP: 0.8276\n",
      "Epoch: 098, AUC: 0.8232, AP: 0.8277\n",
      "Epoch: 099, AUC: 0.8237, AP: 0.8279\n",
      "Epoch: 100, AUC: 0.8239, AP: 0.8281\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Graph Variational AutoEncoder (GVAE)"
   ],
   "metadata": {
    "id": "iQ0vZ05NjO_f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import VGAE"
   ],
   "metadata": {
    "id": "oT8XZ3dPfof4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTBwIZ-_jctx",
    "outputId": "4aa31039-3011-4eeb-a8a6-8abf2de8f631"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels))  # new line\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "id": "rUeXNs4_jfCC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMDGGiSBj1F9",
    "outputId": "31c51f73-b177-414b-f546-383621d8e220"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): VariationalGCNEncoder(\n",
       "    (conv1): GCNConv(3703, 4)\n",
       "    (conv_mu): GCNConv(4, 2)\n",
       "    (conv_logstd): GCNConv(4, 2)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    \n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()  # new line\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ],
   "metadata": {
    "id": "wlR8Y1ULj2m8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "writer = SummaryWriter('runs/VGAE_experiment_'+'2d_100_epochs')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc train',auc,epoch) # new line\n",
    "    writer.add_scalar('ap train',ap,epoch)   # new line"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-ItgS_FkAbq",
    "outputId": "b04262ca-3779-4c74-d967-a9be78064fe1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001, AUC: 0.6081, AP: 0.6439\n",
      "Epoch: 002, AUC: 0.6156, AP: 0.6465\n",
      "Epoch: 003, AUC: 0.6173, AP: 0.6459\n",
      "Epoch: 004, AUC: 0.6177, AP: 0.6459\n",
      "Epoch: 005, AUC: 0.6179, AP: 0.6458\n",
      "Epoch: 006, AUC: 0.6182, AP: 0.6458\n",
      "Epoch: 007, AUC: 0.6184, AP: 0.6459\n",
      "Epoch: 008, AUC: 0.6186, AP: 0.6461\n",
      "Epoch: 009, AUC: 0.6190, AP: 0.6462\n",
      "Epoch: 010, AUC: 0.6193, AP: 0.6465\n",
      "Epoch: 011, AUC: 0.6196, AP: 0.6470\n",
      "Epoch: 012, AUC: 0.6199, AP: 0.6475\n",
      "Epoch: 013, AUC: 0.6201, AP: 0.6479\n",
      "Epoch: 014, AUC: 0.6204, AP: 0.6484\n",
      "Epoch: 015, AUC: 0.6205, AP: 0.6488\n",
      "Epoch: 016, AUC: 0.6210, AP: 0.6495\n",
      "Epoch: 017, AUC: 0.6216, AP: 0.6504\n",
      "Epoch: 018, AUC: 0.6218, AP: 0.6510\n",
      "Epoch: 019, AUC: 0.6222, AP: 0.6520\n",
      "Epoch: 020, AUC: 0.6228, AP: 0.6530\n",
      "Epoch: 021, AUC: 0.6232, AP: 0.6540\n",
      "Epoch: 022, AUC: 0.6234, AP: 0.6544\n",
      "Epoch: 023, AUC: 0.6236, AP: 0.6550\n",
      "Epoch: 024, AUC: 0.6240, AP: 0.6557\n",
      "Epoch: 025, AUC: 0.6241, AP: 0.6560\n",
      "Epoch: 026, AUC: 0.6242, AP: 0.6565\n",
      "Epoch: 027, AUC: 0.6246, AP: 0.6571\n",
      "Epoch: 028, AUC: 0.6247, AP: 0.6580\n",
      "Epoch: 029, AUC: 0.6249, AP: 0.6586\n",
      "Epoch: 030, AUC: 0.6252, AP: 0.6592\n",
      "Epoch: 031, AUC: 0.6254, AP: 0.6597\n",
      "Epoch: 032, AUC: 0.6259, AP: 0.6605\n",
      "Epoch: 033, AUC: 0.6263, AP: 0.6613\n",
      "Epoch: 034, AUC: 0.6270, AP: 0.6624\n",
      "Epoch: 035, AUC: 0.6276, AP: 0.6635\n",
      "Epoch: 036, AUC: 0.6285, AP: 0.6645\n",
      "Epoch: 037, AUC: 0.6289, AP: 0.6654\n",
      "Epoch: 038, AUC: 0.6294, AP: 0.6666\n",
      "Epoch: 039, AUC: 0.6298, AP: 0.6673\n",
      "Epoch: 040, AUC: 0.6304, AP: 0.6684\n",
      "Epoch: 041, AUC: 0.6310, AP: 0.6694\n",
      "Epoch: 042, AUC: 0.6313, AP: 0.6702\n",
      "Epoch: 043, AUC: 0.6314, AP: 0.6710\n",
      "Epoch: 044, AUC: 0.6320, AP: 0.6721\n",
      "Epoch: 045, AUC: 0.6320, AP: 0.6729\n",
      "Epoch: 046, AUC: 0.6322, AP: 0.6738\n",
      "Epoch: 047, AUC: 0.6325, AP: 0.6748\n",
      "Epoch: 048, AUC: 0.6326, AP: 0.6758\n",
      "Epoch: 049, AUC: 0.6328, AP: 0.6766\n",
      "Epoch: 050, AUC: 0.6328, AP: 0.6773\n",
      "Epoch: 051, AUC: 0.6327, AP: 0.6780\n",
      "Epoch: 052, AUC: 0.6331, AP: 0.6791\n",
      "Epoch: 053, AUC: 0.6332, AP: 0.6800\n",
      "Epoch: 054, AUC: 0.6336, AP: 0.6811\n",
      "Epoch: 055, AUC: 0.6340, AP: 0.6822\n",
      "Epoch: 056, AUC: 0.6342, AP: 0.6832\n",
      "Epoch: 057, AUC: 0.6346, AP: 0.6843\n",
      "Epoch: 058, AUC: 0.6347, AP: 0.6853\n",
      "Epoch: 059, AUC: 0.6349, AP: 0.6860\n",
      "Epoch: 060, AUC: 0.6351, AP: 0.6869\n",
      "Epoch: 061, AUC: 0.6354, AP: 0.6879\n",
      "Epoch: 062, AUC: 0.6358, AP: 0.6889\n",
      "Epoch: 063, AUC: 0.6360, AP: 0.6897\n",
      "Epoch: 064, AUC: 0.6363, AP: 0.6906\n",
      "Epoch: 065, AUC: 0.6367, AP: 0.6917\n",
      "Epoch: 066, AUC: 0.6370, AP: 0.6925\n",
      "Epoch: 067, AUC: 0.6373, AP: 0.6936\n",
      "Epoch: 068, AUC: 0.6372, AP: 0.6942\n",
      "Epoch: 069, AUC: 0.6372, AP: 0.6947\n",
      "Epoch: 070, AUC: 0.6376, AP: 0.6957\n",
      "Epoch: 071, AUC: 0.6381, AP: 0.6966\n",
      "Epoch: 072, AUC: 0.6390, AP: 0.6979\n",
      "Epoch: 073, AUC: 0.6394, AP: 0.6988\n",
      "Epoch: 074, AUC: 0.6400, AP: 0.6998\n",
      "Epoch: 075, AUC: 0.6402, AP: 0.7006\n",
      "Epoch: 076, AUC: 0.6406, AP: 0.7013\n",
      "Epoch: 077, AUC: 0.6410, AP: 0.7022\n",
      "Epoch: 078, AUC: 0.6416, AP: 0.7031\n",
      "Epoch: 079, AUC: 0.6422, AP: 0.7041\n",
      "Epoch: 080, AUC: 0.6428, AP: 0.7049\n",
      "Epoch: 081, AUC: 0.6436, AP: 0.7057\n",
      "Epoch: 082, AUC: 0.6445, AP: 0.7067\n",
      "Epoch: 083, AUC: 0.6453, AP: 0.7076\n",
      "Epoch: 084, AUC: 0.6460, AP: 0.7084\n",
      "Epoch: 085, AUC: 0.6474, AP: 0.7094\n",
      "Epoch: 086, AUC: 0.6486, AP: 0.7104\n",
      "Epoch: 087, AUC: 0.6505, AP: 0.7116\n",
      "Epoch: 088, AUC: 0.6527, AP: 0.7130\n",
      "Epoch: 089, AUC: 0.6550, AP: 0.7145\n",
      "Epoch: 090, AUC: 0.6577, AP: 0.7158\n",
      "Epoch: 091, AUC: 0.6601, AP: 0.7173\n",
      "Epoch: 092, AUC: 0.6623, AP: 0.7187\n",
      "Epoch: 093, AUC: 0.6652, AP: 0.7202\n",
      "Epoch: 094, AUC: 0.6683, AP: 0.7217\n",
      "Epoch: 095, AUC: 0.6715, AP: 0.7234\n",
      "Epoch: 096, AUC: 0.6751, AP: 0.7254\n",
      "Epoch: 097, AUC: 0.6781, AP: 0.7271\n",
      "Epoch: 098, AUC: 0.6809, AP: 0.7287\n",
      "Epoch: 099, AUC: 0.6848, AP: 0.7310\n",
      "Epoch: 100, AUC: 0.6887, AP: 0.7332\n",
      "Epoch: 101, AUC: 0.6936, AP: 0.7359\n",
      "Epoch: 102, AUC: 0.6986, AP: 0.7387\n",
      "Epoch: 103, AUC: 0.7029, AP: 0.7414\n",
      "Epoch: 104, AUC: 0.7071, AP: 0.7438\n",
      "Epoch: 105, AUC: 0.7111, AP: 0.7464\n",
      "Epoch: 106, AUC: 0.7143, AP: 0.7486\n",
      "Epoch: 107, AUC: 0.7164, AP: 0.7503\n",
      "Epoch: 108, AUC: 0.7187, AP: 0.7520\n",
      "Epoch: 109, AUC: 0.7209, AP: 0.7534\n",
      "Epoch: 110, AUC: 0.7239, AP: 0.7555\n",
      "Epoch: 111, AUC: 0.7265, AP: 0.7575\n",
      "Epoch: 112, AUC: 0.7296, AP: 0.7599\n",
      "Epoch: 113, AUC: 0.7324, AP: 0.7619\n",
      "Epoch: 114, AUC: 0.7363, AP: 0.7648\n",
      "Epoch: 115, AUC: 0.7403, AP: 0.7677\n",
      "Epoch: 116, AUC: 0.7453, AP: 0.7709\n",
      "Epoch: 117, AUC: 0.7482, AP: 0.7730\n",
      "Epoch: 118, AUC: 0.7511, AP: 0.7749\n",
      "Epoch: 119, AUC: 0.7537, AP: 0.7766\n",
      "Epoch: 120, AUC: 0.7561, AP: 0.7780\n",
      "Epoch: 121, AUC: 0.7582, AP: 0.7793\n",
      "Epoch: 122, AUC: 0.7594, AP: 0.7800\n",
      "Epoch: 123, AUC: 0.7604, AP: 0.7804\n",
      "Epoch: 124, AUC: 0.7613, AP: 0.7809\n",
      "Epoch: 125, AUC: 0.7626, AP: 0.7819\n",
      "Epoch: 126, AUC: 0.7639, AP: 0.7829\n",
      "Epoch: 127, AUC: 0.7646, AP: 0.7832\n",
      "Epoch: 128, AUC: 0.7655, AP: 0.7837\n",
      "Epoch: 129, AUC: 0.7669, AP: 0.7845\n",
      "Epoch: 130, AUC: 0.7681, AP: 0.7852\n",
      "Epoch: 131, AUC: 0.7693, AP: 0.7859\n",
      "Epoch: 132, AUC: 0.7705, AP: 0.7866\n",
      "Epoch: 133, AUC: 0.7714, AP: 0.7872\n",
      "Epoch: 134, AUC: 0.7719, AP: 0.7873\n",
      "Epoch: 135, AUC: 0.7728, AP: 0.7877\n",
      "Epoch: 136, AUC: 0.7738, AP: 0.7884\n",
      "Epoch: 137, AUC: 0.7742, AP: 0.7886\n",
      "Epoch: 138, AUC: 0.7745, AP: 0.7888\n",
      "Epoch: 139, AUC: 0.7746, AP: 0.7888\n",
      "Epoch: 140, AUC: 0.7748, AP: 0.7888\n",
      "Epoch: 141, AUC: 0.7751, AP: 0.7890\n",
      "Epoch: 142, AUC: 0.7754, AP: 0.7893\n",
      "Epoch: 143, AUC: 0.7760, AP: 0.7898\n",
      "Epoch: 144, AUC: 0.7761, AP: 0.7899\n",
      "Epoch: 145, AUC: 0.7763, AP: 0.7899\n",
      "Epoch: 146, AUC: 0.7765, AP: 0.7900\n",
      "Epoch: 147, AUC: 0.7768, AP: 0.7903\n",
      "Epoch: 148, AUC: 0.7772, AP: 0.7905\n",
      "Epoch: 149, AUC: 0.7774, AP: 0.7907\n",
      "Epoch: 150, AUC: 0.7776, AP: 0.7908\n",
      "Epoch: 151, AUC: 0.7777, AP: 0.7909\n",
      "Epoch: 152, AUC: 0.7779, AP: 0.7910\n",
      "Epoch: 153, AUC: 0.7780, AP: 0.7911\n",
      "Epoch: 154, AUC: 0.7780, AP: 0.7910\n",
      "Epoch: 155, AUC: 0.7780, AP: 0.7910\n",
      "Epoch: 156, AUC: 0.7779, AP: 0.7909\n",
      "Epoch: 157, AUC: 0.7779, AP: 0.7907\n",
      "Epoch: 158, AUC: 0.7780, AP: 0.7907\n",
      "Epoch: 159, AUC: 0.7780, AP: 0.7906\n",
      "Epoch: 160, AUC: 0.7780, AP: 0.7905\n",
      "Epoch: 161, AUC: 0.7782, AP: 0.7906\n",
      "Epoch: 162, AUC: 0.7783, AP: 0.7906\n",
      "Epoch: 163, AUC: 0.7782, AP: 0.7904\n",
      "Epoch: 164, AUC: 0.7780, AP: 0.7902\n",
      "Epoch: 165, AUC: 0.7782, AP: 0.7902\n",
      "Epoch: 166, AUC: 0.7783, AP: 0.7902\n",
      "Epoch: 167, AUC: 0.7782, AP: 0.7900\n",
      "Epoch: 168, AUC: 0.7781, AP: 0.7898\n",
      "Epoch: 169, AUC: 0.7781, AP: 0.7898\n",
      "Epoch: 170, AUC: 0.7780, AP: 0.7896\n",
      "Epoch: 171, AUC: 0.7779, AP: 0.7893\n",
      "Epoch: 172, AUC: 0.7779, AP: 0.7893\n",
      "Epoch: 173, AUC: 0.7779, AP: 0.7892\n",
      "Epoch: 174, AUC: 0.7779, AP: 0.7890\n",
      "Epoch: 175, AUC: 0.7782, AP: 0.7890\n",
      "Epoch: 176, AUC: 0.7781, AP: 0.7888\n",
      "Epoch: 177, AUC: 0.7781, AP: 0.7888\n",
      "Epoch: 178, AUC: 0.7781, AP: 0.7887\n",
      "Epoch: 179, AUC: 0.7783, AP: 0.7889\n",
      "Epoch: 180, AUC: 0.7783, AP: 0.7888\n",
      "Epoch: 181, AUC: 0.7781, AP: 0.7886\n",
      "Epoch: 182, AUC: 0.7780, AP: 0.7886\n",
      "Epoch: 183, AUC: 0.7778, AP: 0.7883\n",
      "Epoch: 184, AUC: 0.7779, AP: 0.7882\n",
      "Epoch: 185, AUC: 0.7779, AP: 0.7880\n",
      "Epoch: 186, AUC: 0.7784, AP: 0.7883\n",
      "Epoch: 187, AUC: 0.7785, AP: 0.7882\n",
      "Epoch: 188, AUC: 0.7784, AP: 0.7880\n",
      "Epoch: 189, AUC: 0.7784, AP: 0.7879\n",
      "Epoch: 190, AUC: 0.7782, AP: 0.7877\n",
      "Epoch: 191, AUC: 0.7781, AP: 0.7874\n",
      "Epoch: 192, AUC: 0.7782, AP: 0.7875\n",
      "Epoch: 193, AUC: 0.7781, AP: 0.7874\n",
      "Epoch: 194, AUC: 0.7780, AP: 0.7871\n",
      "Epoch: 195, AUC: 0.7781, AP: 0.7869\n",
      "Epoch: 196, AUC: 0.7785, AP: 0.7873\n",
      "Epoch: 197, AUC: 0.7786, AP: 0.7872\n",
      "Epoch: 198, AUC: 0.7789, AP: 0.7874\n",
      "Epoch: 199, AUC: 0.7792, AP: 0.7875\n",
      "Epoch: 200, AUC: 0.7792, AP: 0.7875\n",
      "Epoch: 201, AUC: 0.7790, AP: 0.7873\n",
      "Epoch: 202, AUC: 0.7786, AP: 0.7868\n",
      "Epoch: 203, AUC: 0.7779, AP: 0.7860\n",
      "Epoch: 204, AUC: 0.7771, AP: 0.7850\n",
      "Epoch: 205, AUC: 0.7773, AP: 0.7850\n",
      "Epoch: 206, AUC: 0.7776, AP: 0.7852\n",
      "Epoch: 207, AUC: 0.7784, AP: 0.7858\n",
      "Epoch: 208, AUC: 0.7788, AP: 0.7862\n",
      "Epoch: 209, AUC: 0.7791, AP: 0.7863\n",
      "Epoch: 210, AUC: 0.7791, AP: 0.7861\n",
      "Epoch: 211, AUC: 0.7787, AP: 0.7855\n",
      "Epoch: 212, AUC: 0.7782, AP: 0.7850\n",
      "Epoch: 213, AUC: 0.7778, AP: 0.7845\n",
      "Epoch: 214, AUC: 0.7773, AP: 0.7838\n",
      "Epoch: 215, AUC: 0.7770, AP: 0.7833\n",
      "Epoch: 216, AUC: 0.7771, AP: 0.7833\n",
      "Epoch: 217, AUC: 0.7776, AP: 0.7837\n",
      "Epoch: 218, AUC: 0.7777, AP: 0.7837\n",
      "Epoch: 219, AUC: 0.7783, AP: 0.7839\n",
      "Epoch: 220, AUC: 0.7786, AP: 0.7840\n",
      "Epoch: 221, AUC: 0.7789, AP: 0.7841\n",
      "Epoch: 222, AUC: 0.7787, AP: 0.7838\n",
      "Epoch: 223, AUC: 0.7779, AP: 0.7829\n",
      "Epoch: 224, AUC: 0.7773, AP: 0.7822\n",
      "Epoch: 225, AUC: 0.7771, AP: 0.7818\n",
      "Epoch: 226, AUC: 0.7774, AP: 0.7820\n",
      "Epoch: 227, AUC: 0.7774, AP: 0.7820\n",
      "Epoch: 228, AUC: 0.7776, AP: 0.7821\n",
      "Epoch: 229, AUC: 0.7780, AP: 0.7824\n",
      "Epoch: 230, AUC: 0.7776, AP: 0.7819\n",
      "Epoch: 231, AUC: 0.7774, AP: 0.7817\n",
      "Epoch: 232, AUC: 0.7768, AP: 0.7810\n",
      "Epoch: 233, AUC: 0.7761, AP: 0.7801\n",
      "Epoch: 234, AUC: 0.7758, AP: 0.7797\n",
      "Epoch: 235, AUC: 0.7760, AP: 0.7799\n",
      "Epoch: 236, AUC: 0.7769, AP: 0.7807\n",
      "Epoch: 237, AUC: 0.7776, AP: 0.7813\n",
      "Epoch: 238, AUC: 0.7783, AP: 0.7820\n",
      "Epoch: 239, AUC: 0.7782, AP: 0.7818\n",
      "Epoch: 240, AUC: 0.7776, AP: 0.7810\n",
      "Epoch: 241, AUC: 0.7769, AP: 0.7800\n",
      "Epoch: 242, AUC: 0.7763, AP: 0.7792\n",
      "Epoch: 243, AUC: 0.7756, AP: 0.7783\n",
      "Epoch: 244, AUC: 0.7757, AP: 0.7783\n",
      "Epoch: 245, AUC: 0.7759, AP: 0.7785\n",
      "Epoch: 246, AUC: 0.7764, AP: 0.7794\n",
      "Epoch: 247, AUC: 0.7774, AP: 0.7804\n",
      "Epoch: 248, AUC: 0.7784, AP: 0.7816\n",
      "Epoch: 249, AUC: 0.7785, AP: 0.7818\n",
      "Epoch: 250, AUC: 0.7782, AP: 0.7815\n",
      "Epoch: 251, AUC: 0.7778, AP: 0.7808\n",
      "Epoch: 252, AUC: 0.7767, AP: 0.7795\n",
      "Epoch: 253, AUC: 0.7765, AP: 0.7790\n",
      "Epoch: 254, AUC: 0.7763, AP: 0.7789\n",
      "Epoch: 255, AUC: 0.7765, AP: 0.7792\n",
      "Epoch: 256, AUC: 0.7775, AP: 0.7804\n",
      "Epoch: 257, AUC: 0.7785, AP: 0.7814\n",
      "Epoch: 258, AUC: 0.7786, AP: 0.7815\n",
      "Epoch: 259, AUC: 0.7783, AP: 0.7811\n",
      "Epoch: 260, AUC: 0.7779, AP: 0.7807\n",
      "Epoch: 261, AUC: 0.7777, AP: 0.7805\n",
      "Epoch: 262, AUC: 0.7774, AP: 0.7801\n",
      "Epoch: 263, AUC: 0.7774, AP: 0.7800\n",
      "Epoch: 264, AUC: 0.7777, AP: 0.7804\n",
      "Epoch: 265, AUC: 0.7780, AP: 0.7806\n",
      "Epoch: 266, AUC: 0.7781, AP: 0.7806\n",
      "Epoch: 267, AUC: 0.7780, AP: 0.7804\n",
      "Epoch: 268, AUC: 0.7778, AP: 0.7802\n",
      "Epoch: 269, AUC: 0.7775, AP: 0.7798\n",
      "Epoch: 270, AUC: 0.7774, AP: 0.7797\n",
      "Epoch: 271, AUC: 0.7776, AP: 0.7799\n",
      "Epoch: 272, AUC: 0.7778, AP: 0.7800\n",
      "Epoch: 273, AUC: 0.7779, AP: 0.7800\n",
      "Epoch: 274, AUC: 0.7782, AP: 0.7803\n",
      "Epoch: 275, AUC: 0.7783, AP: 0.7804\n",
      "Epoch: 276, AUC: 0.7783, AP: 0.7803\n",
      "Epoch: 277, AUC: 0.7782, AP: 0.7800\n",
      "Epoch: 278, AUC: 0.7783, AP: 0.7801\n",
      "Epoch: 279, AUC: 0.7779, AP: 0.7796\n",
      "Epoch: 280, AUC: 0.7781, AP: 0.7797\n",
      "Epoch: 281, AUC: 0.7782, AP: 0.7798\n",
      "Epoch: 282, AUC: 0.7784, AP: 0.7801\n",
      "Epoch: 283, AUC: 0.7787, AP: 0.7803\n",
      "Epoch: 284, AUC: 0.7786, AP: 0.7802\n",
      "Epoch: 285, AUC: 0.7783, AP: 0.7800\n",
      "Epoch: 286, AUC: 0.7780, AP: 0.7798\n",
      "Epoch: 287, AUC: 0.7778, AP: 0.7795\n",
      "Epoch: 288, AUC: 0.7785, AP: 0.7802\n",
      "Epoch: 289, AUC: 0.7789, AP: 0.7806\n",
      "Epoch: 290, AUC: 0.7789, AP: 0.7808\n",
      "Epoch: 291, AUC: 0.7790, AP: 0.7810\n",
      "Epoch: 292, AUC: 0.7788, AP: 0.7807\n",
      "Epoch: 293, AUC: 0.7793, AP: 0.7812\n",
      "Epoch: 294, AUC: 0.7796, AP: 0.7815\n",
      "Epoch: 295, AUC: 0.7795, AP: 0.7814\n",
      "Epoch: 296, AUC: 0.7788, AP: 0.7810\n",
      "Epoch: 297, AUC: 0.7781, AP: 0.7800\n",
      "Epoch: 298, AUC: 0.7775, AP: 0.7793\n",
      "Epoch: 299, AUC: 0.7782, AP: 0.7803\n",
      "Epoch: 300, AUC: 0.7788, AP: 0.7807\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd {PROJECT_PATH}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkZgt2FokCVv",
    "outputId": "398691d3-823e-44eb-bc4b-424569b7732d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: '{PROJECT_PATH}'\n",
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "from os.path import join\n",
    "\n",
    "ROOT = '/content/drive'                                       # default for the drive\n",
    "PROJ = 'MyDrive/CodingProjects'                               # path to your project on Drive\n",
    "\n",
    "GIT_USERNAME = \"rafaelascaciota\"                              # replace with yours\n",
    "GIT_TOKEN = \"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\"        # definitely replace with yours\n",
    "GIT_REPOSITORY = \"CartPole\"                                   # ...nah\n",
    "\n",
    "drive.mount(ROOT, force_remount=True)                         # we mount the drive at /content/drive\n",
    "\n",
    "PROJECT_PATH = join(ROOT, PROJ)\n",
    "!mkdir \"{PROJECT_PATH}\"NEW                                    # in case we haven't created it already   \n",
    "\n",
    "GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\"\n",
    "!mkdir ./temp\n",
    "!git clone \"{GIT_PATH}\"\n",
    "!mv ./temp/* \"{PROJECT_PATH}\"\n",
    "!rm -rf ./temp\n",
    "!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yXiYdMIu4vd",
    "outputId": "5e70d8e3-f502-4e46-859c-6e8bee6a06a5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "mkdir: cannot create directory ‘/content/drive/MyDrive/CodingProjectsNEW’: File exists\n",
      "Cloning into '{GIT_REPOSITORY}'...\n",
      "fatal: unable to access 'https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git/': The requested URL returned error: 400\n",
      "mv: cannot stat './temp/*': No such file or directory\n",
      "sending incremental file list\n",
      "CartPoleDATA.ipynb\n",
      "         16,283 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=2/3)\n",
      "GAE.VGAE.ipynb\n",
      "         41,711 100%   99.11kB/s    0:00:00 (xfr#2, to-chk=1/3)\n",
      "ImgGraph.ipynb\n",
      "          3,098 100%    3.92kB/s    0:00:00 (xfr#3, to-chk=0/3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "DtILoZ1A1XK1"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
