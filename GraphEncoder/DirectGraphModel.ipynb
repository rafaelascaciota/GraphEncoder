{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0e613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.feature_extraction import image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from os.path import join\n",
    "import networkx as nx\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c1977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REGIONS = 25\n",
    "beta = 5\n",
    "eps = 1e-6\n",
    "p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59ccf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r'C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder'\n",
    "os.chdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511d5df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./graph/\n",
      "S9\n",
      "File count: 42\n"
     ]
    }
   ],
   "source": [
    "cam = os.path.join(dir, './data/')\n",
    "latest_subdir = max([os.path.join(cam,d) for d in os.listdir(cam)], key=os.path.getmtime)\n",
    "print(str(latest_subdir))\n",
    "folder = latest_subdir\n",
    "count = 0\n",
    "steps = 0\n",
    "maxPixel= 12\n",
    "imageSize = maxPixel * maxPixel\n",
    "num_features = imageSize\n",
    "\n",
    "cam_graph = os.path.join(dir, './graph/')\n",
    "print(str(cam_graph))\n",
    "all_folders = os.listdir(cam_graph)\n",
    "os.chdir(cam_graph)\n",
    "retval = os.getcwd()\n",
    "all_folders.sort()\n",
    "latest = all_folders[-1].replace('S', '')\n",
    "new = int(latest) + 1\n",
    "mydir = 'S'+str(new)\n",
    "print(str(mydir))\n",
    "os.makedirs(mydir)\n",
    "\n",
    "# Iterate directory\n",
    "for path in os.listdir(folder):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(folder, path)):\n",
    "        count += 1\n",
    "print('File count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06213112",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1602a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame0.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "1\n",
      "1\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame1.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "2\n",
      "2\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame2.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "3\n",
      "3\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame3.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "4\n",
      "4\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame4.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "5\n",
      "5\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame5.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "6\n",
      "6\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame6.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "7\n",
      "7\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame7.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "8\n",
      "8\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame8.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "9\n",
      "9\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame9.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "10\n",
      "10\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame10.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "11\n",
      "11\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame11.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "12\n",
      "12\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame12.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "13\n",
      "13\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame13.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "14\n",
      "14\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame14.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "15\n",
      "15\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame15.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "16\n",
      "16\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame16.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "17\n",
      "17\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame17.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "18\n",
      "18\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame18.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "19\n",
      "19\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame19.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "20\n",
      "20\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame20.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "21\n",
      "21\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame21.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "22\n",
      "22\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame22.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "23\n",
      "23\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame23.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "24\n",
      "24\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame24.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "25\n",
      "25\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame25.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "26\n",
      "26\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame26.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "27\n",
      "27\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame27.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "28\n",
      "28\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame28.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "29\n",
      "29\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame29.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "30\n",
      "30\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame30.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "31\n",
      "31\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame31.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "32\n",
      "32\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame32.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "33\n",
      "33\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame33.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "34\n",
      "34\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame34.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "35\n",
      "35\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame35.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "36\n",
      "36\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame36.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "37\n",
      "37\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame37.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "38\n",
      "38\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame38.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "39\n",
      "39\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame39.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "40\n",
      "40\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame40.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "41\n",
      "41\n",
      "C:\\Users\\mvijitha22\\jupyter_codes\\Rafaela\\GraphEncoder\\GraphEncoder\\./data/S6\\Frame41.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "for f in range(count):\n",
    "    print(str(steps))\n",
    "    print(str(f))\n",
    "    # reading image\n",
    "    data = 'Frame' + str(steps) + '.png'\n",
    "    path = join(folder, data)\n",
    "    print(path)\n",
    "    def read_image():\n",
    "        img = cv2.imread(path, 0)\n",
    "        return img\n",
    "\n",
    "    cartpole = read_image()\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    imageSize=maxPixel*maxPixel\n",
    "    cartpole = resize(cartpole, (maxPixel, maxPixel))\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    # Downsample the image by a factor of 4\n",
    "    print(cartpole.shape)\n",
    "    mask = cartpole.astype(bool)\n",
    "    cartpole = cartpole.astype(float)\n",
    "    print(cartpole.shape)\n",
    "\n",
    "    # Convert the image into a graph with the value of the gradient on the\n",
    "    # edges.\n",
    "    import random\n",
    "\n",
    "    if True:\n",
    "        graph = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        arr = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        graph1 = image.img_to_graph(cartpole)\n",
    "\n",
    "        G = nx.from_numpy_array(arr)\n",
    "        G.edges(data=True)\n",
    "\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "\n",
    "        for i in range(graph.shape[0]):\n",
    "            for j in range(graph.shape[1]):\n",
    "                if graph[i][j] != 0:\n",
    "                    row.append(i)\n",
    "                    col.append(j)\n",
    "                    data.append(graph[i][j])\n",
    "\n",
    "        graph = sp.sparse.coo_matrix((data, (row,col)), shape=graph.shape, dtype = float)\n",
    "    else:\n",
    "        graph = image.img_to_graph(cartpole)\n",
    "\n",
    "    # Take a decreasing function of the gradient: an exponential\n",
    "    # The smaller beta is, the more independent the segmentation is of the\n",
    "    # actual image. For beta=1, the segmentation is close to a voronoi\n",
    "    graph.data = np.exp(-beta * graph.data / cartpole.std()) + eps\n",
    "    #concat graph F\n",
    "    F = nx.compose(F,G)\n",
    "    steps += 1   \n",
    "f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c91f821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x22ce3a85580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8872e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import from_networkx, to_networkx\n",
    "from torch_geometric.data import Data as gData\n",
    "import torch\n",
    "import scipy as sp\n",
    "from torch_geometric.data import Data\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902c357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_graph = from_networkx(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1950ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 336], weight=[336], num_nodes=144)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(required_graph)\n",
    "print(required_graph.x)\n",
    "print(required_graph.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22abbf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_graph.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56098d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2f98536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          41,  42,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  52,\n",
       "          52,  53,  53,  53,  53,  53,  54,  54,  54,  54,  54,  55,  55,  56,\n",
       "          57,  58,  59,  60,  61,  62,  63,  63,  64,  64,  64,  64,  64,  65,\n",
       "          65,  65,  65,  65,  66,  66,  66,  66,  66,  67,  67,  68,  69,  70,\n",
       "          71,  72,  72,  73,  73,  74,  74,  75,  75,  75,  76,  76,  76,  76,\n",
       "          76,  77,  77,  77,  77,  77,  78,  78,  78,  78,  78,  79,  79,  79,\n",
       "          80,  80,  81,  81,  82,  82,  83,  83,  84,  84,  84,  85,  85,  85,\n",
       "          86,  86,  86,  87,  87,  87,  87,  88,  88,  88,  88,  88,  89,  89,\n",
       "          89,  89,  89,  90,  90,  90,  90,  90,  91,  91,  91,  91,  92,  92,\n",
       "          92,  93,  93,  93,  94,  94,  94,  95,  95,  95,  96,  96,  96,  97,\n",
       "          97,  97,  98,  98,  98,  99,  99,  99,  99, 100, 100, 100, 100, 100,\n",
       "         101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103,\n",
       "         103, 104, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107, 107, 107,\n",
       "         108, 108, 108, 109, 109, 109, 110, 110, 110, 111, 111, 111, 111, 112,\n",
       "         112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114,\n",
       "         115, 115, 115, 115, 115, 116, 116, 116, 116, 117, 117, 117, 118, 118,\n",
       "         118, 119, 119, 119, 120, 120, 120, 121, 121, 121, 122, 122, 122, 123,\n",
       "         123, 123, 124, 124, 124, 124, 125, 125, 125, 125, 125, 126, 126, 126,\n",
       "         126, 126, 127, 127, 127, 127, 128, 128, 128, 129, 129, 129, 130, 130,\n",
       "         130, 131, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135, 136, 136,\n",
       "         137, 137, 138, 138, 139, 139, 140, 140, 141, 141, 142, 142, 143, 143],\n",
       "        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          53,  42,  54,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "          64,  41,  52,  53,  54,  65,  42,  53,  54,  55,  66,  54,  55,  56,\n",
       "          57,  58,  59,  60,  61,  62,  63,  64,  52,  63,  64,  65,  76,  53,\n",
       "          64,  65,  66,  77,  54,  65,  66,  67,  78,  66,  67,  68,  69,  70,\n",
       "          71,  72,  84,  73,  85,  74,  86,  75,  87,  76,  64,  75,  76,  77,\n",
       "          88,  65,  76,  77,  78,  89,  66,  77,  78,  79,  90,  78,  79,  91,\n",
       "          80,  92,  81,  93,  82,  94,  83,  95,  72,  84,  96,  73,  85,  97,\n",
       "          74,  86,  98,  75,  87,  99,  88,  76,  87,  88,  89, 100,  77,  88,\n",
       "          89,  90, 101,  78,  89,  90,  91, 102,  79,  90,  91, 103,  80,  92,\n",
       "         104,  81,  93, 105,  82,  94, 106,  83,  95, 107,  84,  96, 108,  85,\n",
       "          97, 109,  86,  98, 110,  87,  99, 100, 111,  88,  99, 100, 101, 112,\n",
       "          89, 100, 101, 102, 113,  90, 101, 102, 103, 114,  91, 102, 103, 104,\n",
       "         115,  92, 103, 104, 116,  93, 105, 117,  94, 106, 118,  95, 107, 119,\n",
       "          96, 108, 120,  97, 109, 121,  98, 110, 122,  99, 111, 112, 123, 100,\n",
       "         111, 112, 113, 124, 101, 112, 113, 114, 125, 102, 113, 114, 115, 126,\n",
       "         103, 114, 115, 116, 127, 104, 115, 116, 128, 105, 117, 129, 106, 118,\n",
       "         130, 107, 119, 131, 108, 120, 132, 109, 121, 133, 110, 122, 134, 111,\n",
       "         123, 135, 112, 124, 125, 136, 113, 124, 125, 126, 137, 114, 125, 126,\n",
       "         127, 138, 115, 126, 127, 139, 116, 128, 140, 117, 129, 141, 118, 130,\n",
       "         142, 119, 131, 143, 120, 132, 121, 133, 122, 134, 123, 135, 124, 136,\n",
       "         125, 137, 126, 138, 127, 139, 128, 140, 129, 141, 130, 142, 131, 143]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_graph.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d835ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28332e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<144x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 336 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix = nx.adjacency_matrix(F)\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e4a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99607843, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.99607843, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.99607843, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.99607843, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.99607843,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.99607843]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_array = nx.to_numpy_array(F) #get adjacence matrix as numpy array\n",
    "adj_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa08caf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'is_multigraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is_multigraph'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-31996762837a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madj_array_second\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequired_graph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get adjacence matrix as numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0madj_array_second\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\convert_matrix.py\u001b[0m in \u001b[0;36mto_numpy_array\u001b[1;34m(G, nodelist, dtype, order, multigraph_weight, weight, nonedge)\u001b[0m\n\u001b[0;32m   1236\u001b[0m     \u001b[1;31m# can be provided.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1239\u001b[0m         \u001b[1;31m# Handle MultiGraphs and MultiDiGraphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \"root folder and try again.\")\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m     64\u001b[0m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'is_multigraph'"
     ]
    }
   ],
   "source": [
    "adj_array_second = nx.to_numpy_array(required_graph) #get adjacence matrix as numpy array\n",
    "adj_array_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5dd4410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 144)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56854ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(F.edges())\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05602e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 144)\n"
     ]
    }
   ],
   "source": [
    "sparse_array = sparse.csr_matrix(adj_matrix).toarray() \n",
    "coo_array = sparse.coo_matrix(adj_matrix)\n",
    "#ArrayG_coo = nx.to_scipy_sparse_array(F, format='coo')\n",
    "print(sparse_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dc848a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = coo_array.data\n",
    "indices = np.vstack((coo_array.row, coo_array.col))\n",
    "\n",
    "datasetG_index = torch.LongTensor(indices)\n",
    "v = torch.FloatTensor(values)\n",
    "shape = sparse_array.shape\n",
    "\n",
    "required_graph.x = torch.sparse.FloatTensor(datasetG_index, v, torch.Size(shape)).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f20b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arr = np.array([F.nodes],dtype=\"float64\")\n",
    "required_graph.y = torch.from_numpy(numpy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6319fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_ratio = 0.2\n",
    "num_nodes = required_graph.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "train_mask = torch.full_like(required_graph.y, False, dtype=bool)\n",
    "#train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(required_graph.y, False, dtype=bool)\n",
    "#test_mask[idx[num_train:]] = True\n",
    "val_mask = test_mask\n",
    "\n",
    "print(train_mask)\n",
    "print(test_mask)\n",
    "print(val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87e08693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_graph.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef8b1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import VGAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "346e26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_nodes = 144\n",
    "num_node_features = required_graph.x.shape[0]\n",
    "num_edge_features = 1\n",
    "\n",
    "x = torch.tensor([num_nodes,num_node_features], dtype=torch.float)\n",
    "\n",
    "data = Data(x=required_graph.x, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24fcdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2e3f242",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_pos_edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train_pos_edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-16fbe9eb8241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_pos_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \"root folder and try again.\")\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m     64\u001b[0m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_pos_edge_index'"
     ]
    }
   ],
   "source": [
    "out_channels = 2\n",
    "num_features = required_graph.x.shape[0]\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels))  # new line\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5778de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
