{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## VGAE applied in a graph form from pairs of frames concatenated to form single input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install packets that we use for the GVAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cpu.html\n",
      "Requirement already satisfied: torch-scatter in c:\\program files\\python39\\lib\\site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in c:\\program files\\python39\\lib\\site-packages (0.6.15)\n",
      "Requirement already satisfied: torch-cluster in c:\\program files\\python39\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: torch-spline-conv in c:\\program files\\python39\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in c:\\program files\\python39\\lib\\site-packages (2.1.0.post1)\n",
      "Requirement already satisfied: scipy in c:\\program files\\python39\\lib\\site-packages (from torch-sparse) (1.9.3)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (1.23.4)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python39\\lib\\site-packages (from torch-geometric) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python39\\lib\\site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\python39\\lib\\site-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python39\\lib\\site-packages (from requests->torch-geometric) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python39\\lib\\site-packages (from requests->torch-geometric) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python39\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python39\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\program files\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\program files\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cpu.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.feature_extraction import image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from os.path import join\n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dir = r'C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder'\n",
    "os.chdir(dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Creating the dataset with frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing steps: 29 rewards -148.17218662487778: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python ./cart_pole_discreet.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Convert images to graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Apply spectral clustering (this step goes much faster if you have pyamg\n",
    "# installed)\n",
    "N_REGIONS = 25\n",
    "beta = 5\n",
    "eps = 1e-6\n",
    "p = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/\n",
      "S4\n",
      "File count: 29\n"
     ]
    }
   ],
   "source": [
    "cam = os.path.join(dir, './data/')\n",
    "latest_subdir = max([os.path.join(cam,d) for d in os.listdir(cam)], key=os.path.getmtime)\n",
    "print(str(latest_subdir))\n",
    "folder = latest_subdir\n",
    "count = 0\n",
    "steps = 0\n",
    "maxPixel= 12\n",
    "imageSize = maxPixel * maxPixel\n",
    "num_features = imageSize\n",
    "\n",
    "cam_graph = os.path.join(dir, './graph/')\n",
    "print(str(cam_graph))\n",
    "all_folders = os.listdir(cam_graph)\n",
    "os.chdir(cam_graph)\n",
    "retval = os.getcwd()\n",
    "all_folders.sort()\n",
    "latest = all_folders[-1].replace('S', '')\n",
    "new = int(latest) + 1\n",
    "mydir = 'S'+str(new)\n",
    "print(str(mydir))\n",
    "os.makedirs(mydir)\n",
    "\n",
    "# Iterate directory\n",
    "for path in os.listdir(folder):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(folder, path)):\n",
    "        count += 1\n",
    "print('File count:', count)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame0.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "1\n",
      "1\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame1.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "2\n",
      "2\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame2.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "3\n",
      "3\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame3.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "4\n",
      "4\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame4.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "5\n",
      "5\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame5.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "6\n",
      "6\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame6.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "7\n",
      "7\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame7.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "8\n",
      "8\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame8.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "9\n",
      "9\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame9.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "10\n",
      "10\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame10.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "11\n",
      "11\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame11.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "12\n",
      "12\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame12.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "13\n",
      "13\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame13.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "14\n",
      "14\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame14.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "15\n",
      "15\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame15.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "16\n",
      "16\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame16.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "17\n",
      "17\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame17.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "18\n",
      "18\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame18.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "19\n",
      "19\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame19.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "20\n",
      "20\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame20.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "21\n",
      "21\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame21.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "22\n",
      "22\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame22.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "23\n",
      "23\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame23.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "24\n",
      "24\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame24.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "25\n",
      "25\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame25.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "26\n",
      "26\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame26.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "27\n",
      "27\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame27.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "28\n",
      "28\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame28.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "for f in range(count):\n",
    "    print(str(steps))\n",
    "    print(str(f))\n",
    "    # reading image\n",
    "    data = 'Frame' + str(steps) + '.png'\n",
    "    path = join(folder, data)\n",
    "    print(path)\n",
    "    def read_image():\n",
    "        img = cv2.imread(path, 0)\n",
    "        return img\n",
    "\n",
    "    cartpole = read_image()\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    imageSize=maxPixel*maxPixel\n",
    "    cartpole = resize(cartpole, (maxPixel, maxPixel))\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    # Downsample the image by a factor of 4\n",
    "    print(cartpole.shape)\n",
    "    mask = cartpole.astype(bool)\n",
    "    cartpole = cartpole.astype(float)\n",
    "    print(cartpole.shape)\n",
    "\n",
    "    # Convert the image into a graph with the value of the gradient on the\n",
    "    # edges.\n",
    "    import random\n",
    "\n",
    "    if True:\n",
    "        graph = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        arr = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        graph1 = image.img_to_graph(cartpole)\n",
    "\n",
    "        G = nx.from_numpy_array(arr)\n",
    "        G.edges(data=True)\n",
    "\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "\n",
    "        for i in range(graph.shape[0]):\n",
    "            for j in range(graph.shape[1]):\n",
    "                if graph[i][j] != 0:\n",
    "                    row.append(i)\n",
    "                    col.append(j)\n",
    "                    data.append(graph[i][j])\n",
    "\n",
    "        graph = sp.sparse.coo_matrix((data, (row,col)), shape=graph.shape, dtype = float)\n",
    "    else:\n",
    "        graph = image.img_to_graph(cartpole)\n",
    "\n",
    "    # Take a decreasing function of the gradient: an exponential\n",
    "    # The smaller beta is, the more independent the segmentation is of the\n",
    "    # actual image. For beta=1, the segmentation is close to a voronoi\n",
    "    graph.data = np.exp(-beta * graph.data / cartpole.std()) + eps\n",
    "    # use the tofile() method\n",
    "    # and use ',' as a separator\n",
    "    # as we have to generate a csv file\n",
    "    arr.tofile(str(mydir) + '\\g'+ str(steps)+'.csv', sep = ',')\n",
    "    # save in graphml\n",
    "    nx.write_graphml_lxml(G, str(mydir) + '\\g'+ str(steps)+'.graphml')\n",
    "    # save in npz\n",
    "    scipy.sparse.save_npz(str(mydir) + '\\g'+ str(steps)+'.npz', graph)\n",
    "    steps += 1\n",
    "f += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Concatenating graphs to have one input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\n",
      "File count .graphml: 29\n"
     ]
    }
   ],
   "source": [
    "folder = str(cam_graph) + str(mydir)\n",
    "f = 0\n",
    "F = nx.Graph()\n",
    "print(str(folder))\n",
    "# Iterate directory\n",
    "counter= len(glob.glob1(folder,\"*.graphml\"))\n",
    "print('File count .graphml:', counter)\n",
    "\n",
    "cmap = plt.get_cmap('plasma')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g0.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g1.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g2.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g3.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g4.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g5.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g6.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g7.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g8.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g9.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g10.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g11.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g12.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g13.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g14.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g15.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g16.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g17.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g18.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g19.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g20.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g21.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g22.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g23.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g24.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g25.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g26.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g27.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g28.graphml\n"
     ]
    }
   ],
   "source": [
    "for f in range(counter):\n",
    "    # reading graph\n",
    "    data = 'g' + str(f) + '.graphml'\n",
    "    path = join(folder, data)\n",
    "    print(path)\n",
    "    def read_graph():\n",
    "        graph = nx.read_graphml(path)\n",
    "        return graph\n",
    "\n",
    "    G = read_graph()\n",
    "    F = nx.compose(F,G)\n",
    "    # nx.draw(F)\n",
    "\n",
    "    # pos = nx.spring_layout(F)\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    # nx.draw_networkx_edges(F, with_labels=False, node_size=50, pos=pos, alpha=.3)# node_color=colors,\n",
    "\n",
    "    # for node in F.nodes():\n",
    "    #     w = plt.pie(\n",
    "    #         [1]*counter,\n",
    "    #         center= pos[node],\n",
    "    #       colors=  cmap.colors([f]),\n",
    "    #        radius=0.05,\n",
    "    #    )\n",
    "f += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(F, str(mydir) + 'Concat.graphml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information about data\n",
    "You have the following attributes:\n",
    "\n",
    "- x the node features, hence it's dimension is number of nodes times feature dimension\n",
    "- edge_index the edge list\n",
    "- y the \"ground truth\"/class labels or in that specific case the classification of the papers. Hence, it's shape is the number of nodes.\n",
    "- The three masks: train_mask, val_mask, test_mask. If I access them via data.train_mask, it gives me a boolean tensor with the length = number of nodes. This is the \"default split\" of the dataset. They should be disjoint and if True the respective node is in that set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] Não foi possível encontrar o procedimento especificado",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_networkx\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch_geometric\\__init__.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModuleType\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m import_module\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloader\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch_geometric\\data\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Data\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhetero_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HeteroData\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtemporal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TemporalData\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch_geometric\\data\\data.py:20\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_sparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparseTensor\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_store\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     23\u001B[0m     FeatureStore,\n\u001B[0;32m     24\u001B[0m     FeatureTensorType,\n\u001B[0;32m     25\u001B[0m     TensorAttr,\n\u001B[0;32m     26\u001B[0m     _field_status,\n\u001B[0;32m     27\u001B[0m )\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_store\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     29\u001B[0m     EDGE_LAYOUT_TO_ATTR_NAME,\n\u001B[0;32m     30\u001B[0m     EdgeAttr,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     34\u001B[0m     edge_tensor_type_to_adj_type,\n\u001B[0;32m     35\u001B[0m )\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch_sparse\\__init__.py:19\u001B[0m\n\u001B[0;32m     17\u001B[0m spec \u001B[38;5;241m=\u001B[39m cuda_spec \u001B[38;5;129;01mor\u001B[39;00m cpu_spec\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find module \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlibrary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_cpu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     22\u001B[0m                       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mosp\u001B[38;5;241m.\u001B[39mdirname(\u001B[38;5;18m__file__\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\_ops.py:573\u001B[0m, in \u001B[0;36m_Ops.load_library\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m    568\u001B[0m path \u001B[38;5;241m=\u001B[39m _utils_internal\u001B[38;5;241m.\u001B[39mresolve_library_path(path)\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dl_open_guard():\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Import the shared library into the process, thus running its\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# static (global) initialization code in order to register custom\u001B[39;00m\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;66;03m# operators with the JIT.\u001B[39;00m\n\u001B[1;32m--> 573\u001B[0m     \u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCDLL\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    574\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded_libraries\u001B[38;5;241m.\u001B[39madd(path)\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\ctypes\\__init__.py:374\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_FuncPtr \u001B[38;5;241m=\u001B[39m _FuncPtr\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 374\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m handle\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 127] Não foi possível encontrar o procedimento especificado"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### open graph created before from several graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "cam_graph = os.path.join(dir, './graph/')\n",
    "mydir = 'S4/S4Concat.graphml'\n",
    "path = str(cam_graph) + str(mydir)\n",
    "graphCONV = nx.read_graphml(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyg_graph = from_networkx(graphCONV)\n",
    "print(pyg_graph)\n",
    "print(pyg_graph.x)\n",
    "print(pyg_graph.y)\n",
    "print(pyg_graph.edge_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_ratio = 0.2\n",
    "num_nodes = pyg_graph.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "train_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "test_mask[idx[num_train:]] = True\n",
    "val_mask = test_mask\n",
    "\n",
    "print(train_mask)\n",
    "print(test_mask)\n",
    "print(val_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Training the VGAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
