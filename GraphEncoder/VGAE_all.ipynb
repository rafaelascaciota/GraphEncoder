{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## VGAE applied in a graph form from pairs of frames concatenated to form single input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install packets that we use for the GVAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-1.11.0%2Bcpu/torch_scatter-2.0.9-cp39-cp39-win_amd64.whl (323 kB)\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.9\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cpu.html\n",
      "Collecting torch-sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-1.11.0%2Bcpu/torch_sparse-0.6.15-cp39-cp39-win_amd64.whl (802 kB)\n",
      "Requirement already satisfied: scipy in c:\\program files\\python39\\lib\\site-packages (from torch-sparse) (1.9.3)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in c:\\program files\\python39\\lib\\site-packages (from scipy->torch-sparse) (1.23.5)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.15\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cpu.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cpu.html\n",
    "!pip install torch-geometric==2.0.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction import image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from os.path import join\n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "dir = r'C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder'\n",
    "os.chdir(dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Creating the dataset with frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing steps: 29 rewards -148.17218662487778: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "!python ./cart_pole_discreet.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Convert images to graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Apply spectral clustering (this step goes much faster if you have pyamg\n",
    "# installed)\n",
    "N_REGIONS = 25\n",
    "beta = 5\n",
    "eps = 1e-6\n",
    "p = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/\n",
      "S4\n",
      "File count: 29\n"
     ]
    }
   ],
   "source": [
    "cam = os.path.join(dir, './data/')\n",
    "latest_subdir = max([os.path.join(cam,d) for d in os.listdir(cam)], key=os.path.getmtime)\n",
    "print(str(latest_subdir))\n",
    "folder = latest_subdir\n",
    "count = 0\n",
    "steps = 0\n",
    "maxPixel= 12\n",
    "imageSize = maxPixel * maxPixel\n",
    "num_features = imageSize\n",
    "\n",
    "cam_graph = os.path.join(dir, './graph/')\n",
    "print(str(cam_graph))\n",
    "all_folders = os.listdir(cam_graph)\n",
    "os.chdir(cam_graph)\n",
    "retval = os.getcwd()\n",
    "all_folders.sort()\n",
    "latest = all_folders[-1].replace('S', '')\n",
    "new = int(latest) + 1\n",
    "mydir = 'S'+str(new)\n",
    "print(str(mydir))\n",
    "os.makedirs(mydir)\n",
    "\n",
    "# Iterate directory\n",
    "for path in os.listdir(folder):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(folder, path)):\n",
    "        count += 1\n",
    "print('File count:', count)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame0.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "1\n",
      "1\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame1.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "2\n",
      "2\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame2.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "3\n",
      "3\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame3.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "4\n",
      "4\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame4.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "5\n",
      "5\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame5.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "6\n",
      "6\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame6.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "7\n",
      "7\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame7.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "8\n",
      "8\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame8.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "9\n",
      "9\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame9.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "10\n",
      "10\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame10.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "11\n",
      "11\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame11.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "12\n",
      "12\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame12.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "13\n",
      "13\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame13.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "14\n",
      "14\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame14.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "15\n",
      "15\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame15.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "16\n",
      "16\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame16.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "17\n",
      "17\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame17.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "18\n",
      "18\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame18.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "19\n",
      "19\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame19.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "20\n",
      "20\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame20.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "21\n",
      "21\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame21.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "22\n",
      "22\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame22.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "23\n",
      "23\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame23.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "24\n",
      "24\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame24.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "25\n",
      "25\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame25.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "26\n",
      "26\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame26.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "27\n",
      "27\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame27.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n",
      "28\n",
      "28\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./data/S4\\Frame28.png\n",
      "img_processing.size= 240000\n",
      "img_processing.size= 144\n",
      "(12, 12)\n",
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "for f in range(count):\n",
    "    print(str(steps))\n",
    "    print(str(f))\n",
    "    # reading image\n",
    "    data = 'Frame' + str(steps) + '.png'\n",
    "    path = join(folder, data)\n",
    "    print(path)\n",
    "    def read_image():\n",
    "        img = cv2.imread(path, 0)\n",
    "        return img\n",
    "\n",
    "    cartpole = read_image()\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    imageSize=maxPixel*maxPixel\n",
    "    cartpole = resize(cartpole, (maxPixel, maxPixel))\n",
    "    print (\"img_processing.size=\",cartpole.size)\n",
    "    # Downsample the image by a factor of 4\n",
    "    print(cartpole.shape)\n",
    "    mask = cartpole.astype(bool)\n",
    "    cartpole = cartpole.astype(float)\n",
    "    print(cartpole.shape)\n",
    "\n",
    "    # Convert the image into a graph with the value of the gradient on the\n",
    "    # edges.\n",
    "    import random\n",
    "\n",
    "    if True:\n",
    "        graph = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        arr = image.img_to_graph(cartpole, mask=mask, return_as=np.ndarray)\n",
    "        graph1 = image.img_to_graph(cartpole)\n",
    "\n",
    "        G = nx.from_numpy_array(arr)\n",
    "        G.edges(data=True)\n",
    "\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "\n",
    "        for i in range(graph.shape[0]):\n",
    "            for j in range(graph.shape[1]):\n",
    "                if graph[i][j] != 0:\n",
    "                    row.append(i)\n",
    "                    col.append(j)\n",
    "                    data.append(graph[i][j])\n",
    "\n",
    "        graph = sp.sparse.coo_matrix((data, (row,col)), shape=graph.shape, dtype = float)\n",
    "    else:\n",
    "        graph = image.img_to_graph(cartpole)\n",
    "\n",
    "    # Take a decreasing function of the gradient: an exponential\n",
    "    # The smaller beta is, the more independent the segmentation is of the\n",
    "    # actual image. For beta=1, the segmentation is close to a voronoi\n",
    "    graph.data = np.exp(-beta * graph.data / cartpole.std()) + eps\n",
    "    # use the tofile() method\n",
    "    # and use ',' as a separator\n",
    "    # as we have to generate a csv file\n",
    "    arr.tofile(str(mydir) + '\\g'+ str(steps)+'.csv', sep = ',')\n",
    "    # save in graphml\n",
    "    nx.write_graphml_lxml(G, str(mydir) + '\\g'+ str(steps)+'.graphml')\n",
    "    # save in npz\n",
    "    scipy.sparse.save_npz(str(mydir) + '\\g'+ str(steps)+'.npz', graph)\n",
    "    steps += 1\n",
    "f += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Concatenating graphs to have one input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\n",
      "File count .graphml: 29\n"
     ]
    }
   ],
   "source": [
    "folder = str(cam_graph) + str(mydir)\n",
    "f = 0\n",
    "F = nx.Graph()\n",
    "print(str(folder))\n",
    "# Iterate directory\n",
    "counter= len(glob.glob1(folder,\"*.graphml\"))\n",
    "print('File count .graphml:', counter)\n",
    "\n",
    "cmap = plt.get_cmap('plasma')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g0.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g1.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g2.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g3.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g4.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g5.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g6.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g7.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g8.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g9.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g10.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g11.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g12.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g13.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g14.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g15.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g16.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g17.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g18.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g19.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g20.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g21.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g22.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g23.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g24.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g25.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g26.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g27.graphml\n",
      "C:\\Users\\rscaciot22\\OneDrive - Oulun yliopisto\\Documents\\2022\\GRAPH_ENCODER\\Simulation\\cart-pole-main\\GraphEncoder\\./graph/S4\\g28.graphml\n"
     ]
    }
   ],
   "source": [
    "for f in range(counter):\n",
    "    # reading graph\n",
    "    data = 'g' + str(f) + '.graphml'\n",
    "    path = join(folder, data)\n",
    "    print(path)\n",
    "    def read_graph():\n",
    "        graph = nx.read_graphml(path)\n",
    "        return graph\n",
    "\n",
    "    G = read_graph()\n",
    "    F = nx.compose(F,G)\n",
    "f += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(F, str(mydir) + 'Concat.graphml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information about data\n",
    "You have the following attributes:\n",
    "\n",
    "- x the node features, hence it's dimension is number of nodes times feature dimension\n",
    "- edge_index the edge list\n",
    "- y the \"ground truth\"/class labels or in that specific case the classification of the papers. Hence, it's shape is the number of nodes.\n",
    "- The three masks: train_mask, val_mask, test_mask. If I access them via data.train_mask, it gives me a boolean tensor with the length = number of nodes. This is the \"default split\" of the dataset. They should be disjoint and if True the respective node is in that set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import from_networkx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open graph created before from several graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "cam_graph = os.path.join(dir, './graph/')\n",
    "mydir = 'S4/S4Concat.graphml'\n",
    "path = str(cam_graph) + str(mydir)\n",
    "graphCONV = nx.read_graphml(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    }
   ],
   "source": [
    "print(len(graphCONV.edges))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "print(len(graphCONV.nodes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the dataset\n",
    "The data object you retrieve from the Planetoid dataset is a single graph. You have the following attributes:\n",
    "\n",
    "x the node features, hence it's dimension is number of nodes (2703) times feature dimension (1433)\n",
    "edge_index the edge list\n",
    "y the \"ground truth\"/class labels or in that specific case the classification of the papers. Hence, it's shape is the number of nodes.\n",
    "The three masks: train_mask, val_mask, test_mask. If I access them via data.train_mask, it gives me a boolean tensor with the length = number of nodes. This is the \"default split\" of the dataset. They should be disjoint and if True the respective node is in that set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "pyg_graph = from_networkx(graphCONV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  12,\n",
      "          13,  13,  14,  14,  15,  15,  16,  16,  17,  17,  18,  18,  19,  19,\n",
      "          20,  20,  21,  21,  22,  22,  23,  23,  24,  24,  24,  25,  25,  25,\n",
      "          26,  26,  26,  27,  27,  27,  28,  28,  28,  29,  29,  29,  30,  30,\n",
      "          30,  31,  31,  31,  32,  32,  32,  33,  33,  33,  34,  34,  34,  35,\n",
      "          35,  35,  36,  36,  37,  37,  38,  38,  39,  39,  39,  40,  40,  40,\n",
      "          40,  40,  41,  41,  41,  41,  41,  42,  42,  42,  42,  42,  43,  43,\n",
      "          43,  43,  43,  44,  44,  44,  44,  45,  45,  46,  46,  47,  47,  48,\n",
      "          48,  49,  49,  50,  50,  51,  51,  51,  52,  52,  52,  52,  52,  53,\n",
      "          53,  53,  53,  53,  54,  54,  54,  54,  54,  55,  55,  55,  55,  55,\n",
      "          56,  56,  56,  56,  56,  57,  57,  57,  58,  58,  59,  59,  60,  60,\n",
      "          60,  61,  61,  61,  62,  62,  62,  63,  63,  63,  63,  64,  64,  64,\n",
      "          64,  64,  65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  67,  67,\n",
      "          67,  67,  67,  68,  68,  68,  68,  68,  69,  69,  69,  69,  70,  70,\n",
      "          70,  71,  71,  71,  72,  72,  72,  73,  73,  73,  74,  74,  74,  74,\n",
      "          75,  75,  75,  75,  75,  76,  76,  76,  76,  76,  77,  77,  77,  77,\n",
      "          77,  78,  78,  78,  78,  78,  79,  79,  79,  79,  79,  80,  80,  80,\n",
      "          80,  80,  81,  81,  81,  81,  82,  82,  82,  83,  83,  83,  84,  84,\n",
      "          84,  85,  85,  85,  85,  86,  86,  86,  86,  86,  87,  87,  87,  87,\n",
      "          87,  88,  88,  88,  88,  88,  89,  89,  89,  89,  89,  90,  90,  90,\n",
      "          90,  90,  91,  91,  91,  91,  91,  92,  92,  92,  92,  92,  93,  93,\n",
      "          93,  93,  94,  94,  94,  95,  95,  95,  96,  96,  96,  97,  97,  97,\n",
      "          97,  98,  98,  98,  98,  98,  99,  99,  99,  99,  99, 100, 100, 100,\n",
      "         100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103,\n",
      "         103, 103, 103, 104, 104, 104, 104, 105, 105, 105, 106, 106, 106, 107,\n",
      "         107, 107, 108, 108, 108, 109, 109, 109, 109, 110, 110, 110, 110, 110,\n",
      "         111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113,\n",
      "         113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116,\n",
      "         116, 117, 117, 117, 118, 118, 118, 119, 119, 119, 120, 120, 120, 121,\n",
      "         121, 121, 121, 122, 122, 122, 122, 122, 123, 123, 123, 123, 123, 124,\n",
      "         124, 124, 124, 124, 125, 125, 125, 125, 125, 126, 126, 126, 126, 126,\n",
      "         127, 127, 127, 127, 127, 128, 128, 128, 128, 129, 129, 129, 130, 130,\n",
      "         130, 131, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135, 136, 136,\n",
      "         137, 137, 138, 138, 139, 139, 140, 140, 141, 141, 142, 142, 143, 143],\n",
      "        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  24,\n",
      "          13,  25,  14,  26,  15,  27,  16,  28,  17,  29,  18,  30,  19,  31,\n",
      "          20,  32,  21,  33,  22,  34,  23,  35,  12,  24,  36,  13,  25,  37,\n",
      "          14,  26,  38,  15,  27,  39,  16,  28,  40,  17,  29,  41,  18,  30,\n",
      "          42,  19,  31,  43,  20,  32,  44,  21,  33,  45,  22,  34,  46,  23,\n",
      "          35,  47,  24,  36,  25,  37,  26,  38,  27,  39,  40,  28,  39,  40,\n",
      "          41,  52,  29,  40,  41,  42,  53,  30,  41,  42,  43,  54,  31,  42,\n",
      "          43,  44,  55,  32,  43,  44,  56,  33,  45,  34,  46,  35,  47,  48,\n",
      "          60,  49,  61,  50,  62,  51,  52,  63,  40,  51,  52,  53,  64,  41,\n",
      "          52,  53,  54,  65,  42,  53,  54,  55,  66,  43,  54,  55,  56,  67,\n",
      "          44,  55,  56,  68,  57,  56,  57,  69,  58,  70,  59,  71,  48,  60,\n",
      "          72,  49,  61,  73,  50,  62,  74,  51,  63,  64,  75,  52,  63,  64,\n",
      "          65,  76,  53,  64,  65,  66,  77,  54,  65,  66,  67,  78,  55,  66,\n",
      "          67,  68,  79,  56,  67,  68,  80,  69,  57,  68,  69,  81,  58,  70,\n",
      "          82,  59,  71,  83,  60,  72,  84,  61,  73,  85,  62,  74,  86,  75,\n",
      "          63,  74,  75,  76,  87,  64,  75,  76,  77,  88,  65,  76,  77,  78,\n",
      "          89,  66,  77,  78,  79,  90,  67,  78,  79,  80,  91,  68,  79,  80,\n",
      "          92,  81,  69,  80,  81,  93,  70,  82,  94,  71,  83,  95,  72,  84,\n",
      "          96,  73,  85,  97,  86,  74,  85,  86,  87,  98,  75,  86,  87,  88,\n",
      "          99,  76,  87,  88,  89, 100,  77,  88,  89,  90, 101,  78,  89,  90,\n",
      "          91, 102,  79,  90,  91,  92, 103,  80,  91,  92, 104,  93,  81,  92,\n",
      "          93, 105,  82,  94, 106,  83,  95, 107,  84,  96, 108,  85,  97, 109,\n",
      "          98,  86,  97,  98,  99, 110,  87,  98,  99, 100, 111,  88,  99, 100,\n",
      "         101, 112,  89, 100, 101, 102, 113,  90, 101, 102, 103, 114,  91, 102,\n",
      "         103, 104, 115,  92, 103, 104, 116,  93, 105, 117,  94, 106, 118,  95,\n",
      "         107, 119,  96, 108, 120,  97, 109, 121, 110,  98, 109, 110, 111, 122,\n",
      "          99, 110, 111, 112, 123, 100, 111, 112, 113, 124, 101, 112, 113, 114,\n",
      "         125, 102, 113, 114, 115, 126, 103, 114, 115, 116, 127, 104, 115, 116,\n",
      "         128, 105, 117, 129, 106, 118, 130, 107, 119, 131, 108, 120, 132, 109,\n",
      "         121, 133, 122, 110, 121, 122, 123, 134, 111, 122, 123, 124, 135, 112,\n",
      "         123, 124, 125, 136, 113, 124, 125, 126, 137, 114, 125, 126, 127, 138,\n",
      "         115, 126, 127, 128, 139, 116, 127, 128, 140, 117, 129, 141, 118, 130,\n",
      "         142, 119, 131, 143, 120, 132, 121, 133, 122, 134, 123, 135, 124, 136,\n",
      "         125, 137, 126, 138, 127, 139, 128, 140, 129, 141, 130, 142, 131, 143]])\n"
     ]
    }
   ],
   "source": [
    "print(pyg_graph.edge_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 144)\n"
     ]
    }
   ],
   "source": [
    "ArrayG_coo = nx.to_scipy_sparse_array(graphCONV, format='coo')\n",
    "print(ArrayG_coo.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "values = ArrayG_coo.data\n",
    "indices = np.vstack((ArrayG_coo.row, ArrayG_coo.col))\n",
    "\n",
    "datasetG_index = torch.LongTensor(indices)\n",
    "v = torch.FloatTensor(values)\n",
    "shape = ArrayG_coo.shape\n",
    "\n",
    "pyg_graph.x = torch.sparse.FloatTensor(datasetG_index, v, torch.Size(shape)).to_dense()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [171], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pyg_graph\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraphCONV\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "pyg_graph.x = torch.sparse.FloatTensor(datasetG_index, v, torch.Size(shape)).to_dense()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_ratio = 0.2\n",
    "num_nodes = pyg_graph.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "train_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "test_mask[idx[num_train:]] = True\n",
    "val_mask = test_mask\n",
    "\n",
    "print(train_mask)\n",
    "print(test_mask)\n",
    "print(val_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Training the VGAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
